{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f99a8a55",
   "metadata": {},
   "source": [
    "# Assignment 4: Instruction finetuning a Llama-2 7B model - part 4\n",
    "## Objective\n",
    "1. Create a dataset of answers generated using Claude-3-Sonnet\n",
    "2. Create a dataset of answers to the same duplicate questions for both Claude-3-Sonnet and Mistral Large\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ec75011-c8ef-4c31-9766-2e3e9834684f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "zsh:1: 0.3.1 not found\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Installing required packages\n",
    "# ----------------\n",
    "! pip install -q -U peft==0.6.2 transformers==4.35.2 datasets==2.15.0 bitsandbytes==0.41.2.post2 trl==0.7.4 accelerate==0.24.1 wandb==0.16.3\n",
    "! pip install -q -U langchain==0.1.13\n",
    "! pip install -q -U safetensors>=0.3.1\n",
    "! pip install -q -U faiss-cpu==1.7.4\n",
    "! pip install -q tiktoken==0.6.0\n",
    "! pip install -q sentence-transformers==2.3.1\n",
    "! pip install -q pypdf==4.0.1\n",
    "! pip install -q protobuf==4.25.2\n",
    "! pip install -q lxml==5.1.0\n",
    "! pip install -q rouge_score==0.1.2\n",
    "! pip install -q beautifulsoup4 boto3\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1447f3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required packages\n",
    "# ----------------\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import CacheBackedEmbeddings, HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "from langchain_community.document_loaders import BSHTMLLoader\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, BitsAndBytesConfig, pipeline\n",
    "from datasets import load_dataset, Dataset\n",
    "from rouge_score import rouge_scorer\n",
    "\n",
    "import torch\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "# ----------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54deb3ed",
   "metadata": {},
   "source": [
    "# SUTD Question Answering RAG system \n",
    "First, we set up the basic RAG system on SUTD content, as you have explored in assignment 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c161e0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘data/SUTD_AnnualReport_2022_23.pdf’ already there; not retrieving.\n",
      "\n",
      "File ‘data/SUTD_AnnualReport_2021.pdf’ already there; not retrieving.\n",
      "\n",
      "File ‘data/SUTD_AnnualReport_2020.pdf’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download SUTD's annual reports\n",
    "! mkdir -p ./data\n",
    "\n",
    "! wget -nc -P data https://www.sutd.edu.sg/SUTD/media/SUTD/SUTD_AnnualReport_2022_23.pdf\n",
    "! wget -nc -P data https://www.sutd.edu.sg/SUTD/media/SUTD/SUTD_AnnualReport_2021.pdf\n",
    "! wget -nc -P data https://www.sutd.edu.sg/SUTD/media/SUTD/SUTD_AnnualReport_2020.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70f76966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  512k    0  512k    0     0  1793k      0 --:--:-- --:--:-- --:--:-- 1798k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  515k    0  515k    0     0  3519k      0 --:--:-- --:--:-- --:--:-- 3506k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  519k    0  519k    0     0  3929k      0 --:--:-- --:--:-- --:--:-- 3937k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  518k    0  518k    0     0  4176k      0 --:--:-- --:--:-- --:--:-- 4212k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  516k    0  516k    0     0  3925k      0 --:--:-- --:--:-- --:--:-- 3913k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  518k    0  518k    0     0  3570k      0 --:--:-- --:--:-- --:--:-- 3575k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  524k    0  524k    0     0  3540k      0 --:--:-- --:--:-- --:--:-- 3545k\n"
     ]
    }
   ],
   "source": [
    "# Download html files from SUTD website\n",
    "! curl --output data/Admission-Requirements.html https://www.sutd.edu.sg/Admissions/Undergraduate/Application/Admission-Requirements\n",
    "! curl --output data/Application-Timeline.html https://www.sutd.edu.sg/Admissions/Undergraduate/Application/Application-Timeline\n",
    "! curl --output data/Singapore-Cambridge-GCE-A-Level.html https://www.sutd.edu.sg/Admissions/Undergraduate/Application/Admission-Requirements/Singapore-Cambridge-GCE-A-Level\n",
    "! curl --output data/Local-Diploma.html https://www.sutd.edu.sg/Admissions/Undergraduate/Application/Admission-Requirements/Local-Diploma\n",
    "! curl --output data/NUS-High-School-Diploma.html https://www.sutd.edu.sg/Admissions/Undergraduate/Application/Admission-Requirements/NUS-High-School-Diploma\n",
    "! curl --output data/International-Baccalaureate-Diploma.html https://www.sutd.edu.sg/Admissions/Undergraduate/Application/Admission-Requirements/International-Baccalaureate-Diploma-\\(Singapore\\)\n",
    "! curl --output data/International-Qualifications.html https://www.sutd.edu.sg/Admissions/Undergraduate/Application/Admission-Requirements/International-Qualifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "810d2d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load file SUTD_AnnualReport_2020.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load file SUTD_AnnualReport_2021.pdf\n",
      "Load file SUTD_AnnualReport_2022_23.pdf\n",
      "Load file Admission-Requirements.html\n",
      "Load file Application-Timeline.html\n",
      "Load file Singapore-Cambridge-GCE-A-Level.html\n",
      "Load file Local-Diploma.html\n",
      "Load file NUS-High-School-Diploma.html\n",
      "Load file International-Baccalaureate-Diploma.html\n",
      "Load file International-Qualifications.html\n",
      "# of Document Pages 148\n",
      "# of Document Chunks: 1042\n"
     ]
    }
   ],
   "source": [
    "# Load the PDF documents and HTML files. Then use LangChain to split the documents into smaller text chunks.\n",
    "data_root = \"./data/\"\n",
    "\n",
    "pdf_filenames = [\n",
    "    'SUTD_AnnualReport_2020.pdf',\n",
    "    'SUTD_AnnualReport_2021.pdf',\n",
    "    'SUTD_AnnualReport_2022_23.pdf',\n",
    "]\n",
    "\n",
    "html_filenames = [\n",
    "    'Admission-Requirements.html',\n",
    "    'Application-Timeline.html',\n",
    "    'Singapore-Cambridge-GCE-A-Level.html',\n",
    "    'Local-Diploma.html',\n",
    "    'NUS-High-School-Diploma.html',\n",
    "    'International-Baccalaureate-Diploma.html',\n",
    "    'International-Qualifications.html'\n",
    "]\n",
    "\n",
    "pdf_metadata = [\n",
    "    dict(year=2020, source=pdf_filenames[0]),\n",
    "    dict(year=2021, source=pdf_filenames[1]),\n",
    "    dict(year=2023, source=pdf_filenames[2])\n",
    "]\n",
    "\n",
    "html_metadata = [\n",
    "    dict(year=2024, source=html_filenames[0]),\n",
    "    dict(year=2024, source=html_filenames[1]),\n",
    "    dict(year=2024, source=html_filenames[2]),\n",
    "    dict(year=2024, source=html_filenames[3]),\n",
    "    dict(year=2024, source=html_filenames[4]),\n",
    "    dict(year=2024, source=html_filenames[5]),\n",
    "    dict(year=2024, source=html_filenames[6])\n",
    "]\n",
    "\n",
    "# load pdf files, attach meta data\n",
    "documents = []\n",
    "for idx, file in enumerate(pdf_filenames):\n",
    "    print(\"Load file\", file)\n",
    "    loader = PyPDFLoader(data_root + file)\n",
    "    document = loader.load()\n",
    "    for document_fragment in document:\n",
    "        document_fragment.metadata = pdf_metadata[idx]\n",
    "    documents += document\n",
    "\n",
    "# load html files, attach meta data\n",
    "for idx, file in enumerate(html_filenames):\n",
    "    print(\"Load file\", file)\n",
    "    loader = BSHTMLLoader(data_root + file)\n",
    "    document = loader.load()\n",
    "    for document_fragment in document:\n",
    "        # remove duplicate whitespace\n",
    "        document_fragment.page_content = repr(re.sub(r\"(?<=\\n)(\\s+)\",r\" \", document_fragment.page_content))\n",
    "        document_fragment.metadata = html_metadata[idx]\n",
    "    documents += document\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=10\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f'# of Document Pages {len(documents)}')\n",
    "print(f'# of Document Chunks: {len(docs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d55752bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings of document chunks and store them in vector store for fast lookup\n",
    "store = LocalFileStore(\"./cache/\")\n",
    "\n",
    "embed_model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "core_embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=embed_model_id\n",
    ")\n",
    "\n",
    "embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    core_embeddings_model, store, namespace=embed_model_id\n",
    ")\n",
    "\n",
    "vector_store = FAISS.from_documents(docs, embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bd4c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "976ead44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load anthropic claude 3 sonnet using AWS bedrock\n",
    "from langchain_community.chat_models.bedrock import BedrockChat\n",
    "llm_sonnet = BedrockChat(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", model_kwargs={\"temperature\": 0.1})\n",
    "llm_mistral_large = BedrockChat(model_id=\"mistral.mistral-large-2402-v1:0\", model_kwargs={\"temperature\": 0.1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate retriever model and callback handler for QA results\n",
    "retriever = vector_store.as_retriever()\n",
    "handler = StdOutCallbackHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build RAG question answering chain with a custom prompt template\n",
    "\n",
    "template = \"\"\"You are a helpful assistant. Use the following pieces of context to answer the question at the end.\n",
    "Answer the following questions about the Singapore University of Technology and Design (SUTD).\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    docs_str = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    # print(docs_str)\n",
    "    return docs_str\n",
    "\n",
    "rag_chain_sonnet = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm_sonnet\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_mistral = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm_mistral_large\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f020cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RAG with example question\n",
    "# rag_chain_sonnet.invoke(\"What types of student organizations and clubs are available on campus?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4446de9e-2698-44b6-8478-7575db0fdf98",
   "metadata": {},
   "source": [
    "Great, we have a working LLM and RAG system about SUTD. Now it is time to generate the answers to the pre defined questions using the Sonnet LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4e785dd-ab6f-41f8-961b-bf6f9ae24a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now create answers to questions using the RAG pipeline\n",
    "\n",
    "# QUESTION: For every question, generate an answer using the RAG system\n",
    "# Store all answers in a list of strings 'answers_all'\n",
    "# Extra points: check that there is diversity in the generated questions, i.e. they are not all the same or too similar.\n",
    "# You can achieve this by checking that questions are not too similar to each other\n",
    "\n",
    "with open('./part1-outputs/questions.txt', 'r') as f:\n",
    "    questions_all = f.readlines()\n",
    "\n",
    "import os\n",
    "\n",
    "sonnet_answers = []\n",
    "mistral_answers = []\n",
    "filename_sonnet = \"./part1-outputs/answers_sonnet.txt\"\n",
    "filename_mistral = \"./part1-outputs/answers_mistral.txt\"\n",
    "\n",
    "# Check if the file exists for the sonnet answers\n",
    "if os.path.exists(filename_sonnet):\n",
    "  # Read the answers from the file\n",
    "  with open(filename_sonnet, \"r\") as f:\n",
    "    sonnet_answers = f.read().split(\"\\n\\n\\n\\n\\n\\n\")\n",
    "else:\n",
    "  # Generate the answers\n",
    "  for question in questions_all:\n",
    "    answer = rag_chain_sonnet.invoke(question)\n",
    "    print(f\"question: {question}\\n answer: {answer}\")\n",
    "    sonnet_answers.append(answer)\n",
    "\n",
    "  # Write the answers to the file\n",
    "  with open(filename_sonnet, \"w\") as f:\n",
    "    for answer in sonnet_answers:\n",
    "      f.write(\"\\n\\n\\n\\n\\n\\n\".join(sonnet_answers))\n",
    "\n",
    "\n",
    "# Check if the file exists: for mistral answers\n",
    "if os.path.exists(filename_mistral):\n",
    "  # Read the answers from the file\n",
    "  with open(filename_mistral, \"r\") as f:\n",
    "    mistral_answers = f.read().split(\"\\n\")\n",
    "else:\n",
    "  # Generate the answers\n",
    "  for question in questions_all:\n",
    "    answer = rag_chain_mistral.invoke(question)\n",
    "    print(f\"question: {question}\\n answer: {answer}\")\n",
    "    mistral_answers.append(answer)\n",
    "\n",
    "  # Write the answers to the file\n",
    "  with open(filename_mistral, \"w\") as f:\n",
    "    for answer in mistral_answers:\n",
    "      f.write(\"\\n\".join(mistral_answers))\n",
    "#---------------------------------\n",
    "len(sonnet_answers)\n",
    "len(mistral_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Sonnet dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ddf2af18-619b-46ef-969e-7e3a61d9a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create huggingface dataset to make it easier to work with the data\n",
    "\n",
    "# QUESTION: create a huggingface dataset object with the keys 'question' and 'answer' and the questions and answers you have generated, respectively\n",
    "# shuffle the dataset. use a fixed seed.\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (5 points)---\n",
    "from datasets import load_dataset, Dataset\n",
    "data = {'question': questions_all, 'answer': sonnet_answers}\n",
    "sutd_qa_dataset_sonnet = Dataset.from_dict(data)\n",
    "#---------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7dde2384-5629-4a22-a3a0-f4c4e8a373dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect schema and size of dataset\n",
    "sutd_qa_dataset_sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b5741823-4129-487e-8c93-3c8f891abe46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are the core academic programs offered at SUTD?\\n',\n",
       " 'answer': 'Based on the context provided, the core academic programs offered at the Singapore University of Technology and Design (SUTD) are:\\n\\n1) Undergraduate programs, which are not explicitly listed but implied by mentions of \"Transition Into SUTD\" and \"Integrated Learning Programme\".\\n\\n2) Master\\'s programs, including Master of Architecture, Master of Engineering (Research), Master of Innovation by Design, Master of Science in Security by Design, Master of Science in Urban Science, Policy and Planning, MSc in Technology and Design, and MTD (AI Empowered Built Environment).\\n\\n3) A Dual Master\\'s program in Nano-Electronic Engineering and Design, offered in collaboration with CGU (likely referring to Claremont Graduate University).'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect first instance\n",
    "sutd_qa_dataset_sonnet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5ad1864-123b-428f-ad9d-09a215541721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset to disk\n",
    "import pickle\n",
    "with open('sutd_qa_dataset_sonnet.pkl', 'wb') as f:\n",
    "    pickle.dump(sutd_qa_dataset_sonnet, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f150acba-379d-474b-8025-fd961118e73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/jon/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# log in to huggingface, you need to put your huggingface access token\n",
    "# https://huggingface.co/docs/hub/en/security-tokens\n",
    "\n",
    "hf_access_token = \"YOUR_HF_ACCESS\"\n",
    "login(token=hf_access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82e3932e-4a76-4693-bc41-daf0d1197f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1461.94ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# push dataset to huggingface\n",
    "sutd_qa_dataset_sonnet.push_to_hub(\"sutd_qa_dataset_sonnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceb295e",
   "metadata": {},
   "source": [
    "Create a Sonnet + Mistral dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c926aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "data = {'question': questions_all + questions_all, 'answer': sonnet_answers + mistral_answers}\n",
    "sutd_qa_dataset_sonnet_mistral = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "87755319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 400\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sutd_qa_dataset_sonnet_mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be10a81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are the core academic programs offered at SUTD?\\n',\n",
       " 'answer': 'Based on the context provided, the core academic programs offered at the Singapore University of Technology and Design (SUTD) are:\\n\\n1) Undergraduate programs, which are not explicitly listed but implied by mentions of \"Transition Into SUTD\" and \"Integrated Learning Programme\".\\n\\n2) Master\\'s programs, including Master of Architecture, Master of Engineering (Research), Master of Innovation by Design, Master of Science in Security by Design, Master of Science in Urban Science, Policy and Planning, MSc in Technology and Design, and MTD (AI Empowered Built Environment).\\n\\n3) A Dual Master\\'s program in Nano-Electronic Engineering and Design, offered in collaboration with CGU (likely referring to Claremont Graduate University).'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sutd_qa_dataset_sonnet_mistral[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c86fef20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are the core academic programs offered at SUTD?\\n',\n",
       " 'answer': \" The Singapore University of Technology and Design (SUTD) offers a variety of academic programs. At the graduate level, they offer Master's programs such as the Master of Architecture, Master of Engineering (Research), Master of Innovation by Design, and Master of Science in Security by Design, among others. They also have a dual Master's program in Nano-Electronic Engineering and Design with CGU. Additionally, SUTD provides opportunities for early matriculation and integrated learning.\"}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sutd_qa_dataset_sonnet_mistral[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db4e09f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset to disk\n",
    "import pickle\n",
    "with open('sutd_qa_dataset_sonnet_mistral.pkl', 'wb') as f:\n",
    "    pickle.dump(sutd_qa_dataset_sonnet_mistral, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "abd7072b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 595.61ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n"
     ]
    }
   ],
   "source": [
    "# push dataset to huggingface\n",
    "sutd_qa_dataset_sonnet_mistral.push_to_hub(\"sutd_qa_dataset_sonnet_mistral\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
