# MLOps Assignment

This repository contains the work for our MLOps assignment. The assignment is divided into several parts, each focusing on a different aspect of the project.

## Part 1
In Part 1, we generate synthetic data using the Llama-2-13b-Nous-Hermes model. The outputs from this process are stored in the `part1-outputs` folder. The dataset on huggingface can be found [here](https://huggingface.co/datasets/jtz18/sutd_qa_dataset)

## Part 2
We fine-tuned our model based on the synthetic data generated in Part 1. The fine-tuned model is publicly available on Hugging Face. You can access it [here](https://huggingface.co/jtz18/llama-7b-qlora-sutd-qa).

## Part 3
In Part 3, we evaluate the performance of our fine-tuned model. The evaluation results are visualized in a Jupyter notebook. We also provide a human evaluation of the model's outputs on the synthetic data, which is available in the `Eval_scores.xlsx` file. This data was generated by the Llama-2-13b-Nous-Hermes model.

## Part 4

In this part, we improve Part 1 by using Amazon Bedrock to call on Claude 3 Sonnet and Mistral Large to generate two datasets. The first dataset uses the predefined questions (same as Part 1) and uses Claude 3 Sonnet LLM to generate answers to the questions. The second dataset uses the Mistral Large model to generate answers to the same predefined questions. This second dataset comprises 400 samples - 200 from Claude 3 Sonnet, 200 from Mistral Large. The idea is that the fine-tuned model should be exposed to a more diverse set of answers for the same question.

- Dataset 1: [Sonnet generated answers](https://huggingface.co/datasets/jtz18/sutd_qa_dataset_sonnet)
- Dataset 2: [Sonnet and Mistral Large generated answers](https://huggingface.co/datasets/jtz18/sutd_qa_dataset_sonnet_mistral)

## Part 5

In this part, we fine-tune two more models:

- A model fine-tuned on Sonnet generated answers (Part 5a) - [huggingface model](https://huggingface.co/jtz18/llama-7b-qlora-sutd-qa-sonnet)
- A model fine-tuned on Sonnet and Mistral generated answers (Part 5b) - [huggingface model](https://huggingface.co/jtz18/llama-7b-qlora-sutd-qa-sonnet-mistral)

## Part 6

In this part, we evaluate the performance of the fine-tuned models:

- We evaluate the fine-tuned Sonnet flavour model (Part 6a)
- We evaluate the fine-tuned Sonnet + Mistral Large flavour model (Part 6b)

In general, we also improve the `ask_sutd_bot` function to truncate any excess output where it attempts to autocomplete a user message after it has replied with its assistant message.

## Notebooks

Parts 4, 5, and 6 are Jupyter notebooks which contain our improvements and the detailed steps of our work.